# â˜ï¸ Mini Project - Building Pipeline in Redshift using DBT-MySQL

Ce projet vise Ã  construire un pipeline de donnÃ©es complet Ã  partir dâ€™un jeu de donnÃ©es brut. Lâ€™objectif est de transformer les donnÃ©es brutes en un schÃ©ma adaptÃ© pour un **Data Warehouse**, permettant dâ€™effectuer des analyses efficaces. Nous dÃ©buterons par une exploration du schÃ©ma initial, qui nÃ©cessitera une **dÃ©normalisation** afin de rÃ©pondre aux besoins analytiques spÃ©cifiques.

---

## **Contexte**
Le jeu de donnÃ©es utilisÃ© dans ce projet provient d'une entreprise de vente au dÃ©tail souhaitant optimiser ses opÃ©rations commerciales. Ce jeu de donnÃ©es contient des informations dÃ©taillÃ©es sur plusieurs aspects de l'activitÃ©, notamment :

- **Suivi des commandes clients** : Identifier qui achÃ¨te quoi, quand, et dans quel magasin.
- **Gestion des stocks** : Suivre les produits commandÃ©s et gÃ©rer les niveaux d'approvisionnement.
- **Analyse des performances des magasins** : Mesurer l'efficacitÃ© des magasins en fonction des commandes traitÃ©es, des ventes rÃ©alisÃ©es, et des taux de taxe appliquÃ©s.
- **Optimisation des coÃ»ts** : Ã‰valuer les coÃ»ts des approvisionnements, particuliÃ¨rement ceux des articles pÃ©rissables, pour mieux gÃ©rer les marges.

Lâ€™objectif global pour lâ€™entreprise est de mieux comprendre son activitÃ© et de prendre des dÃ©cisions Ã©clairÃ©es concernant :
- La gestion des stocks.
- Lâ€™optimisation des prix.
- La maximisation des ventes.

---

## ğŸ¯**Objectifs et technologies**
Le projet repose sur lâ€™utilisation de **DBT (Data Build Tool)** pour orchestrer les transformations de donnÃ©es, et dâ€™**Amazon Redshift** pour hÃ©berger lâ€™entrepÃ´t de donnÃ©es. Ce cadre technique nous permettra de travailler efficacement sur la transformation et la structuration des donnÃ©es tout en amÃ©liorant nos compÃ©tences en **SQL** et en modÃ©lisation.

## ğŸ¯**Objectifs du projet :**
1. **CrÃ©er un schÃ©ma adaptÃ© pour un Data Warehouse** :
   - Simplifier les requÃªtes analytiques.
   - Optimiser les performances pour lâ€™analyse.

2. **ImplÃ©menter un pipeline de donnÃ©es reproductible** :
   - Transformer les donnÃ©es brutes en tables dÃ©normalisÃ©es prÃªtes Ã  lâ€™analyse.

3. **AmÃ©liorer les compÃ©tences techniques** :
   - Appliquer les concepts de modÃ©lisation des donnÃ©es.
   - Renforcer l'expertise en **ETL (Extract, Transform, Load)** et en **data modeling**.
